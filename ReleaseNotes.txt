Version 3.3 (10/15/09)


Updates:

1. Upgraded the underlining XNA framework from 3.0 to 3.1. 

2. Added support for ALVAR optical marker tracking library. Tutorial 8 now includes an example of using ALVAR.

3. Added automatic marker array image and configuration generation tool (MarkerLayout) under tools directory.

4. Added State.DebugTextColor to specify the color of the debug texts such as FPS and triangle count.

5. Added DoneEvent event member to GoblinXNA.Helpers.Interpolator class so that the user can assign functions to be 
   triggered when the interpolation finishes. (Has restriction on the usage. Please check API doc)

6. Added support for implementing custom comparer for sorting the drawing order of transparent geometries. You can
   now set Scene.TransparencyDrawOrderComparer to your custom comparer.

7. Added 3D text drawing capability using Nuclex.Fonts library (http://nuclexframework.codeplex.com)
   Now you can draw a 3D text using GoblinXNA.UI.UI3D.UI3DRenderer's Write3DText(...) functions. An
   example is provided in Tutorial 9.  

8. Added UI2DRenderer.FillPolygon(...) method for polygon drawing (concave polygon doesn't work yet).

9. Finished G2DSpinner and G2DList implementation.

10. Added G2DSuggestField which is a text field that is capable of showing a suggestion list under the text field.
    This new class is added to GoblinXNA.UI.UI2D.Fancy package.


Bug Fixes:

1. The lag of marker transformations relative to the displayed video image has been removed when 
   State.IsMultiCore is set to true.

2. Fixed bounding volume computation of models that are not centered at the origin. This problem caused some models
   to be clipped (not rendered) even though they are in the view frustum.

3. Fixed G2DSlider not to function when it is not visible. 

4. Fixed bounds problem for cascaded G2DPanel component.

5. Added focus highlight and null character caret blinking for G2DTextField. Also, fixed the caret position display
   when HorizontalAlignment is set to other than Left.


Improvements:

1. Improved transparency handling.

2. Converted Vector3 calculations to inline in order to increase the computation speed on either Update and Draw path
   and methods called frequently.

3. Optimized 2D shape & text drawing by deferring the actual drawing until UI2DRenderer.Flush() is called. Now you can
   call UI2DRenderer's drawing functions either before or after base.Draw(..) function (It used to be that you have to
   call the 2D drawing functions after base.Draw(..)). Now, if you call the 2D drawing functions after base.Draw(..),
   then you will need to call UI2DRenderer.Flush() after all of your 2D drawing calls in order to display them on the
   current frame. Otherwise, it will be deferred till the following frame. However, if you want to draw 2D shapes or
   texts on top of the 2D UI widgets created using G2D objects, then you have to call your 2D drawing functions after
   base.Draw(..). Otherwise, your 2D drawings will appear beneath the G2D objects.


Changes:

1. When a Node is added to a BranchNode subclasses through AddChild, it used to override the Enabled property of the
   added Node to be the same as its parent's Enabled property value, but this is changed so that it won't override.

2. Removed the GoblinXNA.UI.Events package, and converted all of the listener based event triggering implementations
   to C# 'event' based implementation. This change removes the neccessity of creating multiple internal classes to
   handle events and needs to create static member variables. Also, this is more intuitive in C# environment to use
   event properties instead of Java-like listener implementation.

3. Modified the GenericInput class for easier and more intuitive navigation using mouse-dragging.

4. The constant strings in InputMapper and DeviceEnumerator are removed. Please use the Identifier property
   of each InputDevice or InputDevice_6DOF classes to specify the device name (e.g., use 
   MouseInput.Instance.Identifier instead of InputMapper.Mouse to get the mouse device name)


Version 3.2 (4/24/09)


1. Added ImageFormat enum in IVideoCapture class that specifies the format of ImagePtr property, which
   will be passed to the marker tracker library. ImageFormat parameter is added to the InitVideoCapture(...)
   function. Prior to this change, the format of ImagePtr was always R8G8B8_24 format which works for
   ARTag.

2. Removed audioDeviceID parameter from IVideoCapture's InitVideoCapture(...) function since it's unlikely
   that anyone will use the audio input that comes with the webcam. Also, if you see the discussion post,
   it puts weird restriction on the resolution of the video device when audio device is used, so it's more
   harmful than useful to have the audioDeviceID parameter.

3. Changed MarkerNode constructors' last parameter's type from "params String[]" to "params Object[]".

4. GenericInput, KeyboardInput, MouseInput, GPS, InterSense, and InputMapper classes are now singleton 
   classes, so you should use the Instance property to access their instantiations. 

5. Fixed tutorial 11 problem, and modified tutorial 8 to match the changes listed in 1 and 2.

6. Added a "tools" folder, and the visual debugging tool (SceneGraphDisplay) is included. 

7. GPS and InterSense classes are not automatically initialized by the InputMapper class anymore, so you
   need to create their instance and initialize them yourself, and add them to InputMapper class through 
   InputMapper.AddInputDevice(...) or InputMapper.Add6DOFInputDevice(...) functions if you want to use either 
   InterSense or GPS device. After you add them, make sure to call InputMapper.Reenumerate() function. 

8. Due to the changes in 7, you don't need the InterSenseEnable, InterSenseHost, or InterSensePort setting
   variables in the setting file to use InterSense anymore. Instead, you should directly pass those parameters
   (host name and port number) to InterSense constructor if you want to connect to it through network server.

9. Added VUZIX's iWear VR920 (which is a stereoscopic display with orientation tracking) support, and the 
   classes can be found in GoblinXNA.Device.iWear package.

10. Removed InputDeviceDriver class since it's not used anymore.

11. Fixed undeterministic behavior when adding nodes. If a node is added to the scene graph while the scene
    graph is being traversed, it can cause undeterministic behavior. This problem has been fixed.

12. Added GetClosestPoint(..) method in NewtonPhysics.

13. Added additional placement options for Notifier class. Now it allows custom starting location and
    transition direction. 
   
14. IMarkerTracker interface now requires ZNearPlane and ZFarPlane property.

15. Added tutorial 13 for iWear VR920 stereo demo.

16. Added LeftEyeVideoID, RightEyeVideoID, LeftEyeVideoImageShift, and RightEyeVideoImageShift properties 
    to Scene class in order to support stereo video overlay.

17. Added VideoVisibleArea property to Scene class so that the visible area of the video image rendered on the
    background can be modified. Be default, it rendres the entire video image when ShowCameraImage is set to
    true.

18. Fixed re-addition of Newton joints when RestartSimulation() is called in NewtonPhysics. 



Version 3.1 (2/18/09)


1. Addition of Tutorial 12 that demonstrates advanced physics functionalities including joint
   physics and vehicle physics simulation.


2. Significant structural and design changes for video capturing and marker tracking for better
   flexibility and extensibility.

   a) Point Grey (PGRFly) related classes are moved under GoblinXNA.Device.Capture.PointGrey package.

   b) Marker tracking related utility classes are moved from GoblinXNA.Device.Vision.Util to
      GoblinXNA.Device.Util.

   c) VideoCapture class is now gone. Instead, IVideoCapture interface is added and each different
      video streaming classes are implemented in its own class that extend this IVideoCapture interface
      (e.g., DirectShowCapture, PointGreyCapture). Now if you want to create your own video streaming
      class that uses other video streaming library, you simply implement IVideoCapture interface. 
      You can then add it to Scene class to use it for either marker tracking or simply displaying 
      the video image on the background. Prior to this change, you had to modify the VideoCapture class
      inside the Goblin XNA and recompile the library if you want to create your own streaming class. 
      Now, you can implement the class outside of Goblin XNA, and you don't need to modify and recompile 
      Goblin XNA. 

   d) MarkerTracker class is now gone. Instead, IMarkerTracker interface is added. ARTagTracker class
      implements this interface using ARTag library. If you want to implement your own marker tracking
      class using another tracker library and use it with Goblin XNA, you simply need to implement this
      interface and assign your tracker implementation to Scene.MarkerTracker. 


3. Modifications and additions in the Scene class due to the redesign.

   a) Scene.InitMarkerModules(...) function is removed.

   b) Scene.InitVideoCapture(...) function is replaced with Scene.AddVideoCapture(...) function. The
      signature of the function changed, so please see the API documentation as well as the tutorial 8
      for modification details. Before you can add a video capture device, you need to initialize the
      device by calling InitVideoCapture(...) function with appropriate parameters.

   c) Scene.InitMarkerTracker(...) function is replaced with Scene.MarkerTracker property. Now you can
      directly set the IMarkerTracker implementation you want to use to Scene.MarkerTracker. Before you
      can set the marker tracker, you need to initialize it.

   d) Added Scene.TrackerVideoID property which is used to specifiy which capture device to use for
      performing the tracking when there are more than one video capture devices. Prior to this, the
      Scene.OverlayVideoID was used to specify which capture device to use, but now, they are separated.
      This means that you can show a different video overlay image on the background from the video image
      you use for performing the tracking. This is useful when you have a camera that is used only for 
      tracking hand gestures that use attached markers on the fingers or hand, and a separate camera to
      visualize the physical world. 

   e) Added Scene.FreezeVideo property which can be used to freeze the video streaming. (Note that the
      video image is frozen, but the virtual world is not frozen).


4. MarkerNode's constructor signature is modified, and new properties are added.

   a) Due to the changes to MarkerTracker class, we removed the arTagArrayName parameter since the
      marker tracking library may not necessary be ARTag. Instead, we added markerConfigs parameter
      which is an array of String that can specify the marker configurations for any type of marker
      tracker library. 

   b) We removed the smoothingAlpha parameter, but instead, we added Smoother property which can be set to
      any implementation of ISmoother interface. This way, the programmer has the choice of what smoothing
      algorithm to apply instead of forced to use our DES (double-exponential-smoothing) implementation.

   c) We added Predictor property which can be set to any implementation of IPredictor interface. This 
      predictor is used to predict the marker transform when the marker can not be found in the image
      for a few frames.


5. UserData property is added to the Node class which is the ancestor of all Node types. Since it's an Object
   type, you can associate any type of information to a Node by using this UserData property. 


6. Added Smoother and Predictor properties to TrackerNode.


7. Added AddInputDevice(..), Add6DOFInputDevice(..), and Reenumerate() functions to InputMapper class, so now
   you can add your own implemented InputDevice or InputDevice_6DOF class to the InputMapper, and use it with
   the TrackerNode. After you add a new device to InputMapper, make sure to call Reenumerate() so that the
   newly added device is recognized.

   
      
   